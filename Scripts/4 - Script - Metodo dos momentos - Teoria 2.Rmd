---
title: "Relat√≥rio de Teoria - Script "
output:
  html_document:
    df_print: paged
---
# Metodo #

Para estima√ß√£o da distribui√ß√£o foi utilizado o m√©todo:

**Param√©trico**  

Esse m√©todo √© utilizado para poucas observa√ß√µes. √â atribuido a ele uma distribui√ß√£o conhecida (distribui√ß√£o te√≥rica)

**N√£o Param√©trico**

Esse m√©todo √© utilizado para um grande n√∫mero de observa√ß√µes. Nesse caso aplicamos uma distribui√ß√£o emp√≠rica.






**Organizando o banco de dados**
```{r}
setwd("D:/Google Drive/2 - Ufpb/P5/Teoria/Prova/")
```

```{r}
#transformando dados em uma lista de tamanho 12.

dados=list()
length(dados)=12
for(i in 1:12){
  dados[[i]]=read.csv(paste("grupo4am",i,".csv",sep=""))
}
#S √© uma lista numerica com 12 informa√ß√µes
S=c()
N=c()
N=numeric(12)
S=numeric(12)
```

```{r eval=FALSE, include=FALSE}
#visualizando as listas
dados

#Para encontrar resultados mensais

N[i]=dim(dados[[i]][1,])
S[i]=sum(dados[[i]][,2])
```

#
#
#
#
#

## Respostas da Letra A ##

**Separando as informa√ß√µes**

    Come√ßando pela an√°lise do banco de dados, este √© formado por 455 observa√ß√µes onde encontramos os valores da severidade da carteira (x) e da frequ√™ncia dos sinistros.

  **Severidade = X**
```{r}
#Criando um objeto apenas para a severidade

x <-c((dados[[1]][,2]),(0), (dados[[3]][,2]), (dados[[4]][,2]), (dados[[5]][,2]), (dados[[6]][,2]), (dados[[7]][,2]), (dados[[8]][,2]), (dados[[9]][,2]), (dados[[10]][,2]), (dados[[11]][,2]), (dados[[12]][,2]))
```

  **Frequencia = n**
```{r}
#Criando um objeto apenas para a frequ√™ncia

n <-c((dados[[1]][,1]), (dados[[2]][,1]), (dados[[3]][,1]), (dados[[4]][,1]), (dados[[5]][,1]), (dados[[6]][,1]), (dados[[7]][,1]), (dados[[8]][,1]), (dados[[9]][,1]), (dados[[10]][,1]), (dados[[11]][,1]), (dados[[12]][,1]))
```

**Histogramas**

```{r}
#analisando o histograma √© possivel ver que os dados n√£o tem forma normal.
hist(n)
```
    O histograma do n√∫mero de sinistros(n) ocorridos em 1 ano mostra que os dados est√£o concentrados na parte esquerda do gr√°fico, ou seja, a carteira da seguradora hipot√©tica √© mais frequente acontecerem uma quantidade  sinistros entre 0 e 40 por ano

```{r}
hist(x)
```
    O histograma da severidade  que √© do valor de cada sinistro na carteira se concentra nos valores acima de $ 90.000 ent√£o podemos interpretar que para essa carteira o valor m√≠nimo a ser pago √© de $ 90.000.


**Severidade da Carteira**


```{r}
#Dados[[1]][,2] = Primeiro da lista, segunda coluna

S=sum((dados[[1]][,2]), (dados[[3]][,2]), (dados[[4]][,2]), (dados[[5]][,2]), (dados[[6]][,2]), (dados[[7]][,2]), (dados[[8]][,2]), (dados[[9]][,2]), (dados[[10]][,2]), (dados[[11]][,2]), (dados[[12]][,2]))
S
```

```{r}
Ex <- mean(x)
Vx <- var(x)
Dpx <- sd(x)
CVx <- Dpx / Ex
```

```{r}
Ex   #M√©dia dos valores de x
Vx   #Variancia dos valores de x
Dpx   #Desvio padr√£o dos valores de x
CVx   #Coeficiente de varia√ß√£o de x
```
   O valor m√©dio pago √© de $ 99780.44, esses valores est√£o dispersos $ 21978146, est√£o dispersos da m√©dia $ 4688.086 e a medida de variabilidade da m√©dia √© de 4%.



**Frequ√™ncia observada da carteira**

```{r}
En <- mean(n)
Vn <- var(n)
Dpn <- sd(n)
CVn <- Dpn / En
```

```{r}
En   #M√©dia dos valores de n
Vn   #Variancia dos valores de n
Dpn   #Desvio padr√£o dos valores de n
CVn   #Coeficiente de varia√ß√£o de s
```
    A quantidade m√©dia de sinistros ocorridos √© 34.6, a vari√¢ncia que √© quanto os valores est√£o dispersos do valor esperado √© de 740.9, o desvio padr√£o √© uma medida de dispers√£o em rela√ß√£o a m√©dia para esses dados ele √© de 27.2 e o coeficiente de varia√ß√£o √© de 78% mede a extens√£o da variabilidade em rela√ß√£o √† m√©dia.


**Sinistro Agregado**

    E[Scol] = E[N]*E[X] 
  
    V[Scol] = V[X]*E[N] + E[X]2 *V[N]`
  
```{r}
Es <- (En*Ex)
Vs <- (En*Vx)+(Ex)^2*Vn
Ds <- sqrt(Vs)
CVs <- Ds/Es
```

```{r}
Es   #M√©dia dos valores de S
Vs   #Variancia dos valores de S
Ds   #Desvio padr√£o dos valores de S
CVs   #Desvio padr√£o dos valores de S
```
    O Sinistro Agregado √© a indeniza√ß√£o total da carteira em um ano ent√£o de acordo com os dados acima o valor esperado de indeniza√ß√µes e de $ 3452184, a vari√¢ncia √© de 7.37, o desvio padr√£o 2716155 e a medida de variabilidade da m√©dia √© de 78%.



**Pr√™mio Puro com 1% de nivel de signific√¢ncia**

  Pp=E[s]+Z(1-a)*DesvioS
  
```{r}
#qnorm retorna o Z(1-a)

PP1 = Es+qnorm(1-0.01)*Ds
PP5 = Es+qnorm(1-0.05)*Ds
PP10 = Es+qnorm(1-0.10)*Ds

```

```{r}
PP1   #Pr√™mio puro com 1% de signific√¢ncia
PP5   #Pr√™mio puro com 5% de signific√¢ncia
PP10   #Pr√™mio puro com 10% de signific√¢ncia
```
    Calculo do Pr√™mio Puro quando S tem distribui√ß√£o que se aproxima da Normal 



**Pr√™mio Puro pela f√≥rmula**

  teta = (Z(1-a)*DesvioS)/Es
  
  Pp = E[s]*(1+teta) 
  
```{r}
#Carregamentos para 1%, 5%, 10% de signific√¢ncia

teta1=((qnorm(1-0.01)*Ds)/Es)
teta5=((qnorm(1-0.05)*Ds)/Es)
teta10=((qnorm(1-0.1)*Ds)/Es)

```

```{r}
teta1   #Carregamento com 1% de signific√¢ncia
teta5   #Carregamento com 5% de signific√¢ncia
teta10   #Carregamento com 10% de signific√¢ncia
```

```{r}
#Premio puro para 1%, 5%, 10% de signific√¢ncia

Pp1 = Es*(1+teta1)
Pp5 = Es*(1+teta5)
Pp10 = Es*(1+teta10)
```

```{r}
Pp1   #Pr√™mio puro com 1% de signific√¢ncia
Pp5   #Pr√™mio puro com 5% de signific√¢ncia
Pp10   #Pr√™mio puro com 10% de signific√¢ncia
```
    Foram feitos 3 c√°lculos para diferentes n√≠veis de signific√¢ncia 1%, 5% e 10% e isto afeta diretamente o valor de ∆ü.
#
#
#
#
#

## Respostas da Letra B ##

**Par√¢metros r, p da binomial**

```{r}
p = En/Vn
r = (En*p)/(1-p)
p
r
```



**Par√¢metros a e b pelo metodos do momentos**

```{r}
#Transformando a media e vari√¢ncia em m1 e m3
m1 <- Ex
m3 <- Vx
```

```{r}
a = ((m1)^2)/m3
b = m1/m3
b
a
```



**Gerando N aleatoriamente**

```{r}
#rnbinom cria valores diacordo com o tamanho e os parametros encontrados.
nb = rnbinom(500, r, p)
nb
```

**Gerando um X e S que dependem de N aleatorio.**

```{r}
#Criando um Sb que depende do Nb do ambiente anterior, onde Xb segue uma gamma aleatoria de tamanho n, e parametros a e b.
Sb=numeric(500)
for(i in 1:500){
  xb = rgamma(nb[i], a, b)
  Sb = sum(xb)
}
Sb
```


**Refazendo o pr√™mio puro com o novo banco de dados:**


**Severidade da Carteira B**

```{r}
xb   #Severidade B
Sb   #Sinistro Agregado B
```

```{r}
Exb <- mean(xb)
Vxb <- var(xb)
Dpxb <- sd(xb)
CVxb <- Dpxb / Exb
```

```{r}
Exb   #M√©dia dos valores de xb
Vxb   #Variancia dos valores de xb
Dpxb   #Desvio padr√£o dos valores de xb
CVxb  #Coeficiente de varia√ß√£o de xb
```



**Frequ√™ncia observada da carteira B**

```{r}
Enb <- mean(nb)
Vnb <- var(nb)
Dpnb <- sd(nb)
CVnb <- Dpnb / Enb
```

```{r}
Enb   #M√©dia dos valores de nb
Vnb   #Variancia dos valores de nb
Dpnb   #Desvio padr√£o dos valores de nb
CVnb   #Coeficiente de varia√ß√£o de nb
```



**Sinistro Agregado B**

    E[Scol] = E[N]*E[X] 
  
    V[Scol] = V[X]*E[N] + E[X]2 *V[N]`
  
```{r}
Esb <- (Enb*Exb)
Vsb <- (Enb*Vxb)+(Exb)^2*Vnb
Dsb <- sqrt(Vsb)
CVsb <- Dsb/Esb
```

```{r}
Esb   #M√©dia dos valores de Sb
Vsb  #Variancia dos valores de Sb
Dsb   #Desvio padr√£o dos valores de Sb
CVsb   #Desvio padr√£o dos valores de Sb
```



**Pr√™mio Puro com 1% de nivel de signific√¢ncia B**

    #qnorm retorna o Z(1-a)
   
    Pp=E[s]+Z(1-a)*DesvioS
   
```{r}
PPb1 = Esb+qnorm(1-0.01)*Dsb
PPb5 = Esb+qnorm(1-0.05)*Dsb
PPb10 = Esb+qnorm(1-0.10)*Dsb

```

```{r}
PPb1   #Pr√™mio puro com 1% de signific√¢ncia
PPb5   #Pr√™mio puro com 5% de signific√¢ncia
PPb10   #Pr√™mio puro com 10% de signific√¢ncia
```




**Pr√™mio Puro pela f√≥rmula B**

  teta = (Z(1-a)*DesvioS)/Es
  
  Pp = E[s]*(1+teta) 
  
```{r}
#Carregamentos para 1%, 5%, 10% de signific√¢ncia

tetab1=((qnorm(1-0.01)*Dsb)/Esb)
tetab5=((qnorm(1-0.05)*Dsb)/Esb)
tetab10=((qnorm(1-0.1)*Dsb)/Esb)

```

```{r}
tetab1   #Carregamento com 1% de signific√¢ncia
tetab5   #Carregamento com 5% de signific√¢ncia
tetab10   #Carregamento com 10% de signific√¢ncia
```

```{r}
#Premio puro para 1%, 5%, 10% de signific√¢ncia

Ppb1 = Esb*(1+tetab1)
Ppb5 = Esb*(1+tetab5)
Ppb10 = Esb*(1+tetab10)
```

```{r}
Ppb1   #Pr√™mio puro com 1% de signific√¢ncia
Ppb5   #Pr√™mio puro com 5% de signific√¢ncia
Ppb10   #Pr√™mio puro com 10% de signific√¢ncia
```
#
#
#
#
#
#
#
#
#
#
#
#
#

## Testes ##



**Teste de Normalidade**
Usando a fun√ß√£o shapiro.test() temos a informa√ß√£o se a vari√°vel tem caracter√≠sticas de uma distribui√ß√£o normal. Para esse teste se (W < p-value) ent√£o rejeitamos a hip√≥tese nula, ou seja, o objeto n√£o segue distribui√ß√£o normal.

```{r}
#n√£o sei se faz sentido fazer o testes de normalidade para a severidade
shapiro.test(n)   #teste para a frequ√™ncia da letra a
shapiro.test(nb)   #teste para a frequ√™ncia da letra b
shapiro.test(x)   #teste para a severidade da letra a
shapiro.test(xb)  #teste para a severidade da letra b
```

**Histogramas de nb e xb**

```{r}
hist(nb)
hist(xb)
```



**TesteS de Ader√™ncia**
O teste ks observa a m√°xima difer√™n√ßa absoluta entre a fun√ß√£o de distribui√ß√£o te√≥rica e a  fun√ß√£o de distribui√ß√£o emp√≠rica. Sua hip√≥tese nula √© que os dados seguem uma distribui√ß√£o escolhida (No nosso exemplo, Gamma ou Binomial). J√° a hip√≥tese alternativa √© que os dados n√£o seguem a distribui√ß√£o escolhhida. 
Quanto menor for a estat√≠stica de D, mais pr√≥xima da distribui√ß√£o te√≥rica assumida, est√° a distrinui√ß√£o emp√≠rica.

**Para a Severidade**
```{r}
ks.test(x, "pgamma", a, b)
ks.test(xb, "pgamma", a, b)
```
**Para a Frequ√™ncia**
```{r}
ks.test(n, "rnbinom", r, p)
ks.test(nb, "rnbinom", r, p)
```

#
#
#
#
#

$$
Pp= E[S]*(1+Œ∏)
$$
 
$$
E[X]= ‚àë x*p(x)
$$

$$
E[X]=bŒ±/Œ≤ùõΩùõΩ
$$

$$
V[X]= Œ±/(Œ≤^2)
$$

$$
E[X^2]=‚àë (x^2)*p(x)
$$

$$
V[X]= E[X^2]-{E[X]^2}
$$

$$
Dp[X]= ‚àö(v[x])
$$

$$
Cv[X]= (Dp[x])/(E[x])  
$$

$$
E[N]= (r*q)/p
$$

$$
V[N]= (r*q)/(p^2)
$$

$$
Dp(N)= ‚àö(v[N]) 
$$

$$
Cv[N]=(Dp[N])/(E[N])  
$$

$$
E[Scol] = E[N]*E[X] 
$$

$$
V[Scol] = V[X]*E[N] + E[X]2 *V[N] 
$$

$$
Dp[Scol]= ‚àö(V[Scol]) 
$$  

$$
Cv[Scol]=(Dp[S])/(E[S])
$$

$$
p = En/Vn
$$    

$$
r = (En*p)/(1-p)
$$    



